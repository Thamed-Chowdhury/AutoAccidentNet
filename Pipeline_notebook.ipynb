{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Inputs #\n",
    "Gemini_API_Keys = [\n",
    "    \"YOUR API 1\",\n",
    "    \"YOUR API 2\"\n",
    "    ]\n",
    "newspaper_name = \"UNB\"\n",
    "date = \"10-01-2025\"\n",
    "API = Gemini_API_Keys[-1] # Choose any\n",
    "url = \"https://unb.com.bd/category/14/Bangladesh\"\n",
    "DEBUG = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline codes and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Codes #\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"Starting test for Newspaper: **   {newspaper_name}   **\")\n",
    "print(\"---------------------------------------------------\")\n",
    "\n",
    "# Function to check if a newspaper name exists in a file and return its type\n",
    "def check_newspaper_type(newspaper_name):\n",
    "    pagination_file = \"pagination_website_lists.txt\"\n",
    "    dynamic_file = \"dynamic_website_lists.txt\"\n",
    "\n",
    "    # Check in pagination file\n",
    "    try:\n",
    "        with open(pagination_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            if newspaper_name in file.read().splitlines():\n",
    "                return \"The website is of type pagination.\"\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    # Check in dynamic file\n",
    "    try:\n",
    "        with open(dynamic_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            if newspaper_name in file.read().splitlines():\n",
    "                return \"The website is of type dynamic.\"\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    return \"Error-404: The newspaper name is not found in either list. Generate Scraping Code First.\"\n",
    "\n",
    "\n",
    "# Check the type of the newspaper\n",
    "result = check_newspaper_type(newspaper_name)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n",
    "\n",
    "infinite = False\n",
    "if \"Error-404\" in result:\n",
    "    # Webpage Classification #\n",
    "    import webpage_classifier_agent\n",
    "    webpage_type = webpage_classifier_agent.classifier(API, url).split('<type>')[1]\n",
    "    print(webpage_type)\n",
    "\n",
    "    print(f\"Starting scraping code generation for newspaper: {newspaper_name}\")\n",
    "    if 'pagination' in webpage_type:\n",
    "        import pagination_code_writer_agent\n",
    "        pagination_code_writer_agent.paginate_code_writer(url, newspaper_name, API)\n",
    "        # Append the newspaper name to the appropriate file\n",
    "        file_name = \"pagination_website_lists.txt\"\n",
    "        with open(file_name, \"a\", encoding=\"utf-8\") as file:\n",
    "            file.write(newspaper_name + \"\\n\")\n",
    "    elif 'dynamic' in webpage_type:\n",
    "        import dynamic_code_writer_agent\n",
    "        dynamic_code_writer_agent.dynamic_code_writer(API, url, newspaper_name)\n",
    "        file_name = \"dynamic_website_lists.txt\"\n",
    "        with open(file_name, \"a\", encoding=\"utf-8\") as file:\n",
    "            file.write(newspaper_name + \"\\n\")\n",
    "    elif 'Infinite' in webpage_type:\n",
    "        result = \"The website is of type Infinite Scroll\"\n",
    "        infinite = True\n",
    "    else:\n",
    "        print(\"Error: Could not classify the webpage.\")\n",
    "    if infinite == False:\n",
    "        # Check the type of the newspaper after code generation\n",
    "        result = check_newspaper_type(newspaper_name)\n",
    "\n",
    "print(\"result variable: \", result)\n",
    "from datetime import datetime\n",
    "def days_between_today_and(date_str):\n",
    "    \"\"\"\n",
    "    Calculate the number of days between today and the given date.\n",
    "\n",
    "    Parameters:\n",
    "        date_str (str): The target date as a string in the format 'YYYY-MM-DD'.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of days between today and the given date.\n",
    "            Positive if the date is in the future, negative if in the past.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse the input date string\n",
    "        target_date = datetime.strptime(date_str, '%d-%m-%Y').date()\n",
    "        \n",
    "        # Get today's date\n",
    "        today_date = datetime.today().date()\n",
    "        \n",
    "        # Calculate the difference in days\n",
    "        delta = (target_date - today_date).days\n",
    "        \n",
    "        return delta\n",
    "    except ValueError:\n",
    "        return \"Invalid date format. Please use 'DD-MM-YYYY'.\"\n",
    "    \n",
    "print(f\"-------------------  Main Output for newspaper:     {newspaper_name}   -------------------------\")\n",
    "\n",
    "if 'pagination' in result:\n",
    "    no_of_pages_to_scrape = (abs(days_between_today_and(date)) + 1) * 3\n",
    "    ## Importing Button Click Function ##\n",
    "    import importlib.util\n",
    "\n",
    "    # Specify the module's path\n",
    "    module_path = f\"{newspaper_name}/button_click.py\"\n",
    "    module_name = \"button_click\"\n",
    "\n",
    "    # Load the module\n",
    "    spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "    url_list = module.pagination_url_collector(no_of_pages_to_scrape)\n",
    "\n",
    "    import pagination_title_link_collector\n",
    "    news_df = pagination_title_link_collector.collect(API, url_list)\n",
    "    news_df.drop_duplicates(inplace=True)\n",
    "    news_df.reset_index(drop=True, inplace=True)\n",
    "    print(\"Total number of news to be processed: \",len(news_df))\n",
    "    if DEBUG == True:\n",
    "        news_df = news_df.head(10)\n",
    "    len(news_df)\n",
    "\n",
    "    import report_processor_agent\n",
    "    final_df = report_processor_agent.report_processor(news_df, Gemini_API_Keys)\n",
    "elif 'dynamic' in result:\n",
    "    no_of_button_click = (abs(days_between_today_and(date)) + 1) * 2\n",
    "    # import universal_dynamic_title_link\n",
    "    # news_df = universal_dynamic_title_link.title_link_dict_func(API, url, newspaper_name, no_of_button_click)\n",
    "\n",
    "    import universal_dynamic_title_link_div\n",
    "    news_df = universal_dynamic_title_link_div.title_link_dict_func(API, url, newspaper_name, no_of_button_click)\n",
    "\n",
    "    print(\"Total number of news to be processed: \",len(news_df))\n",
    "    if DEBUG == True:\n",
    "        news_df = news_df.head(10)\n",
    "    import report_processor_agent\n",
    "    final_df = report_processor_agent.report_processor(news_df, Gemini_API_Keys)\n",
    "elif 'Infinite' in result:\n",
    "    import infinite_scroll_title_link\n",
    "    no_of_button_click = (abs(days_between_today_and(date)) + 1) * 2\n",
    "    news_df = infinite_scroll_title_link.title_link_dict_func(API, url, newspaper_name, no_of_button_click)\n",
    "    print(\"Total number of news to be processed: \",len(news_df))\n",
    "    if DEBUG == True:\n",
    "        news_df = news_df.head(10)\n",
    "    import report_processor_agent\n",
    "    final_df = report_processor_agent.report_processor(news_df, Gemini_API_Keys)\n",
    "else:\n",
    "    print(\"ERROR: Could not identify website type\")\n",
    "\n",
    "print(final_df.head(10))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmscrape2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
